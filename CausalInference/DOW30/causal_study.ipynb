{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "The company's financial report factors have a causal impact on quarterly returns, with adjustments made to account for the confounding influences of the specified year, quarter, sector, and additional treatment-specific confounders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dowhy import CausalModel\n",
    "from fundamental_feature_engineer import build_fundamental_features, scale_features\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet = pd.read_csv('./DOW30_balance_sheet.csv')\n",
    "cash_flow = pd.read_csv('./DOW30_cash_flow.csv')\n",
    "income_statement = pd.read_csv('./DOW30_income_statement.csv')\n",
    "stock_prices = pd.read_csv('./DOW30.csv')\n",
    "\n",
    "balance_sheet['date'] = pd.to_datetime(balance_sheet['date'])\n",
    "cash_flow['date'] = pd.to_datetime(cash_flow['date'])\n",
    "income_statement['date'] = pd.to_datetime(income_statement['date'])\n",
    "stock_prices['date'] = pd.to_datetime(stock_prices['date'])\n",
    "stock_prices['return'] = stock_prices.groupby('ticker')['adjClose'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoting the dataframes\n",
    "pivot_balance_sheet = balance_sheet.pivot_table(index=['ticker', 'date', 'year', 'quarter'], columns='dataCode', values='value').reset_index()\n",
    "pivot_cash_flow = cash_flow.pivot_table(index=['ticker', 'date', 'year', 'quarter'], columns='dataCode', values='value').reset_index()\n",
    "pivot_income_statement = income_statement.pivot_table(index=['ticker', 'date', 'year', 'quarter'], columns='dataCode', values='value').reset_index()\n",
    "\n",
    "financial_data = pivot_balance_sheet.merge(pivot_cash_flow, on=['ticker', 'date', 'year', 'quarter'], suffixes=('_balance', '_cash'))\n",
    "financial_data = financial_data.merge(pivot_income_statement, on=['ticker', 'date', 'year', 'quarter'], suffixes=('', '_income'))\n",
    "financial_data = financial_data.loc[~(financial_data.quarter == 0)] # remove annual one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataCode</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>accoci</th>\n",
       "      <th>acctPay</th>\n",
       "      <th>acctRec</th>\n",
       "      <th>assetsCurrent</th>\n",
       "      <th>assetsNonCurrent</th>\n",
       "      <th>cashAndEq</th>\n",
       "      <th>...</th>\n",
       "      <th>return_on_capital_employed</th>\n",
       "      <th>long_term_debt_to_capitalization</th>\n",
       "      <th>receivables_turnover</th>\n",
       "      <th>fixed_asset_turnover</th>\n",
       "      <th>dividend_payout_ratio</th>\n",
       "      <th>dividend_coverage_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>operating_margin</th>\n",
       "      <th>cash_flow_margin</th>\n",
       "      <th>equity_multiplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.114700e+10</td>\n",
       "      <td>5.426800e+10</td>\n",
       "      <td>7.647000e+09</td>\n",
       "      <td>7.851100e+10</td>\n",
       "      <td>1.665420e+11</td>\n",
       "      <td>1.057500e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.492685</td>\n",
       "      <td>19.916438</td>\n",
       "      <td>0.914490</td>\n",
       "      <td>-0.811181</td>\n",
       "      <td>-1.232770</td>\n",
       "      <td>1.358731</td>\n",
       "      <td>0.040971</td>\n",
       "      <td>0.030420</td>\n",
       "      <td>3.384476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.081800e+10</td>\n",
       "      <td>5.657600e+10</td>\n",
       "      <td>7.891000e+09</td>\n",
       "      <td>8.203200e+10</td>\n",
       "      <td>1.730890e+11</td>\n",
       "      <td>1.388800e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045640</td>\n",
       "      <td>0.470086</td>\n",
       "      <td>20.483082</td>\n",
       "      <td>0.933809</td>\n",
       "      <td>-0.190488</td>\n",
       "      <td>-5.249674</td>\n",
       "      <td>1.451505</td>\n",
       "      <td>0.045263</td>\n",
       "      <td>0.083944</td>\n",
       "      <td>3.206810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.157300e+10</td>\n",
       "      <td>6.104900e+10</td>\n",
       "      <td>8.625000e+09</td>\n",
       "      <td>8.839100e+10</td>\n",
       "      <td>1.707830e+11</td>\n",
       "      <td>1.215400e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>0.466083</td>\n",
       "      <td>18.643942</td>\n",
       "      <td>0.941569</td>\n",
       "      <td>-2.385692</td>\n",
       "      <td>-0.419166</td>\n",
       "      <td>0.815158</td>\n",
       "      <td>0.038569</td>\n",
       "      <td>0.005056</td>\n",
       "      <td>3.261856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.130200e+10</td>\n",
       "      <td>5.681200e+10</td>\n",
       "      <td>8.796000e+09</td>\n",
       "      <td>7.687700e+10</td>\n",
       "      <td>1.755220e+11</td>\n",
       "      <td>9.867000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>0.453660</td>\n",
       "      <td>19.712142</td>\n",
       "      <td>0.987842</td>\n",
       "      <td>-0.270166</td>\n",
       "      <td>-3.701434</td>\n",
       "      <td>1.509408</td>\n",
       "      <td>0.041837</td>\n",
       "      <td>0.096385</td>\n",
       "      <td>3.009730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.136700e+10</td>\n",
       "      <td>5.607100e+10</td>\n",
       "      <td>9.075000e+09</td>\n",
       "      <td>7.715200e+10</td>\n",
       "      <td>1.769020e+11</td>\n",
       "      <td>9.405000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>0.462255</td>\n",
       "      <td>17.797025</td>\n",
       "      <td>0.912980</td>\n",
       "      <td>-0.314867</td>\n",
       "      <td>-3.175943</td>\n",
       "      <td>0.974813</td>\n",
       "      <td>0.042357</td>\n",
       "      <td>0.026308</td>\n",
       "      <td>3.125165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "dataCode ticker       date  year  quarter        accoci       acctPay  \\\n",
       "440         WMT 2023-04-30  2023        1 -1.114700e+10  5.426800e+10   \n",
       "441         WMT 2023-07-31  2023        2 -1.081800e+10  5.657600e+10   \n",
       "442         WMT 2023-10-31  2023        3 -1.157300e+10  6.104900e+10   \n",
       "444         WMT 2024-01-31  2023        4 -1.130200e+10  5.681200e+10   \n",
       "445         WMT 2024-04-30  2024        1 -1.136700e+10  5.607100e+10   \n",
       "\n",
       "dataCode       acctRec  assetsCurrent  assetsNonCurrent     cashAndEq  ...  \\\n",
       "440       7.647000e+09   7.851100e+10      1.665420e+11  1.057500e+10  ...   \n",
       "441       7.891000e+09   8.203200e+10      1.730890e+11  1.388800e+10  ...   \n",
       "442       8.625000e+09   8.839100e+10      1.707830e+11  1.215400e+10  ...   \n",
       "444       8.796000e+09   7.687700e+10      1.755220e+11  9.867000e+09  ...   \n",
       "445       9.075000e+09   7.715200e+10      1.769020e+11  9.405000e+09  ...   \n",
       "\n",
       "dataCode  return_on_capital_employed  long_term_debt_to_capitalization  \\\n",
       "440                         0.013188                          0.492685   \n",
       "441                         0.045640                          0.470086   \n",
       "442                         0.005760                          0.466083   \n",
       "444                         0.032657                          0.453660   \n",
       "445                         0.030875                          0.462255   \n",
       "\n",
       "dataCode  receivables_turnover  fixed_asset_turnover  dividend_payout_ratio  \\\n",
       "440                  19.916438              0.914490              -0.811181   \n",
       "441                  20.483082              0.933809              -0.190488   \n",
       "442                  18.643942              0.941569              -2.385692   \n",
       "444                  19.712142              0.987842              -0.270166   \n",
       "445                  17.797025              0.912980              -0.314867   \n",
       "\n",
       "dataCode  dividend_coverage_ratio  cash_ratio  operating_margin  \\\n",
       "440                     -1.232770    1.358731          0.040971   \n",
       "441                     -5.249674    1.451505          0.045263   \n",
       "442                     -0.419166    0.815158          0.038569   \n",
       "444                     -3.701434    1.509408          0.041837   \n",
       "445                     -3.175943    0.974813          0.042357   \n",
       "\n",
       "dataCode  cash_flow_margin  equity_multiplier  \n",
       "440               0.030420           3.384476  \n",
       "441               0.083944           3.206810  \n",
       "442               0.005056           3.261856  \n",
       "444               0.096385           3.009730  \n",
       "445               0.026308           3.125165  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_data = build_fundamental_features(financial_data)\n",
    "financial_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the closest trading day\n",
    "def find_closest_next_trading_day(target_date):\n",
    "    future_dates = stock_prices[stock_prices['date'] >= target_date]\n",
    "    if len(future_dates):\n",
    "        return future_dates.iloc[0]['date']\n",
    "    return None\n",
    "\n",
    "def find_closest_previous_trading_day(target_date):\n",
    "    past_dates = stock_prices[stock_prices['date'] < target_date] # can't be exactly at the end of report day\n",
    "    if len(past_dates):\n",
    "        return past_dates.iloc[-1]['date']\n",
    "    return None\n",
    "\n",
    "def calculate_next_returns(df):\n",
    "    df = df.sort_values('date')\n",
    "    df['start_date'] = df['date'].apply(find_closest_next_trading_day)\n",
    "    df['next_date'] = df['date'].shift(-1).apply(find_closest_previous_trading_day)\n",
    "    df = df.merge(stock_prices[['ticker', 'date', 'adjClose']].rename(columns={'date': 'start_date'}), on=['ticker', 'start_date'], how='left')\n",
    "    df = df.merge(stock_prices[['ticker', 'date', 'adjClose']].rename(columns={'date': 'next_date', 'adjClose': 'next_adjClose'}), on=['ticker', 'next_date'], how='left')\n",
    "    df['quarterly_return'] = (df['next_adjClose'] - df['adjClose']) / df['adjClose']\n",
    "    return df\n",
    "\n",
    "\n",
    "unique_dates = financial_data[['ticker', 'date']].drop_duplicates().sort_values(['ticker', 'date'])\n",
    "returns_data = unique_dates.groupby('ticker').apply(calculate_next_returns).reset_index(drop=True)\n",
    "returns_data = returns_data.dropna()\n",
    "financial_data = financial_data.dropna(axis=1) # the lastest report will be dropped as it has no next report (next_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_data = pd.merge(financial_data, returns_data[['ticker', 'date', 'quarterly_return']], on=['ticker', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a subset to study, where the IC > 0.02 and the confounders abs corr > 0.4 with the feature\n",
    "# this may lead to a group of similar indicators (multicollinearity) in the end, \n",
    "# but as the rest confounders are controlled, it increases the robustness\n",
    "\n",
    "numeric_corr = fundamental_data.select_dtypes(include=np.number).drop(columns=['year', 'quarter']).corr()\n",
    "numeric_return_corr = numeric_corr['quarterly_return'].sort_values(key=abs, ascending=False)\n",
    "\n",
    "feature_study_list = numeric_return_corr[numeric_return_corr.abs() > 0.02].drop('quarterly_return').index.tolist()\n",
    "strong_corrs = numeric_corr[(numeric_corr.abs() > 0.4) & (numeric_corr < 0.8)] # numeric_corr != 1.0\n",
    "causal_study = {k: [x for x, y in v.items() if not np.isnan(y)] for k, v in strong_corrs[feature_study_list].to_dict().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the causal_study mapping, causal_study # {treatment: [confounders]}\n",
    "with open('./CausalData/causal_study.json', 'w') as json_file:\n",
    "    json.dump(causal_study, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add T-Bill\n",
    "\n",
    "DOW30_sector = pd.read_csv('./DOW30_sector.csv')\n",
    "DOW30_sector = pd.Series(DOW30_sector.sector.values, index=DOW30_sector.ticker).to_dict()\n",
    "fundamental_data['sector'] = fundamental_data['ticker'].map(DOW30_sector)\n",
    "\n",
    "rf_rates = pd.read_excel('./RiskFree20Yr.xls', usecols=['TcmDate', 'Tcm10yr'])\n",
    "rf_rates['TcmDate'] = pd.to_datetime(rf_rates['TcmDate'])\n",
    "rf_rates = rf_rates.rename({'TcmDate':'date', 'Tcm10yr':'T_Bill'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Separate the numeric and non-numeric columns\n",
    "numeric_cols = fundamental_data.select_dtypes(include=np.number).columns\n",
    "non_numeric_cols = fundamental_data.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# Fill missing values in numeric columns with the median\n",
    "fundamental_data[numeric_cols] = fundamental_data[numeric_cols].fillna(fundamental_data[numeric_cols].median())\n",
    "\n",
    "# Combine the numeric and non-numeric columns back together\n",
    "fundamental_data = pd.concat([fundamental_data[numeric_cols], fundamental_data[non_numeric_cols]], axis=1)\n",
    "\n",
    "# Encode columns using one-hot encoding\n",
    "data = pd.get_dummies(fundamental_data, columns=['ticker', 'quarter', 'sector']) # don't controll the year\n",
    "\n",
    "rf_rates.set_index('date', inplace=True)\n",
    "full_date_range = pd.date_range(start=data.date.min(), end=data.date.max(), freq='D')\n",
    "rf_rates = rf_rates.reindex(full_date_range).ffill().bfill().reset_index()\n",
    "rf_rates.rename(columns={'index': 'date'}, inplace=True)\n",
    "\n",
    "data = data.merge(rf_rates, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_columns = data.select_dtypes(exclude=np.number).columns\n",
    "data = scale_features(data, 'quarterly_return', non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the preprocessed data\n",
    "data.to_csv('./CausalData/DOW30_fundamental.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = []\n",
    "\n",
    "ticker_list = data.columns[data.columns.str.contains('ticker.*')].tolist()\n",
    "quarter_list = data.columns[data.columns.str.contains('quarter.*') & ~data.columns.str.contains('quarterly_return')].tolist()\n",
    "sector_list = data.columns[data.columns.str.contains('sector.*')].tolist()\n",
    "\n",
    "for treatment_feature, treat_confounders in causal_study.items():\n",
    "    outcome_feature = 'quarterly_return'\n",
    "    confounders = ticker_list + quarter_list + treat_confounders + sector_list + ['T_Bill']\n",
    "\n",
    "    model = CausalModel(\n",
    "        data=data,\n",
    "        treatment=treatment_feature,\n",
    "        outcome=outcome_feature,\n",
    "        common_causes=confounders\n",
    "    )\n",
    "    \n",
    "    identified_estimand = model.identify_effect()\n",
    "    causal_estimate = model.estimate_effect(identified_estimand, method_name=\"backdoor.linear_regression\")\n",
    "    estimates.append((treatment_feature, causal_estimate, model, identified_estimand))\n",
    "    print(f\"Linear Regression Estimate for {treatment_feature}:\", causal_estimate.value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_causal_estimate(metric_name, causal_estimate, model, identified_estimand):\n",
    "    # print(f\"Processing {metric_name}...\")\n",
    "\n",
    "    result = {\n",
    "        'metric_name': metric_name,\n",
    "        'causal_estimate': causal_estimate.value,\n",
    "    }\n",
    "\n",
    "    # Perform refutation tests\n",
    "    refute_placebo = model.refute_estimate(\n",
    "        identified_estimand, causal_estimate, method_name=\"placebo_treatment_refuter\"\n",
    "    )\n",
    "\n",
    "    refute_subset = model.refute_estimate(\n",
    "    identified_estimand, causal_estimate, method_name=\"data_subset_refuter\"\n",
    "    )\n",
    "\n",
    "    refute_random = model.refute_estimate(\n",
    "        identified_estimand, causal_estimate, method_name=\"random_common_cause\"\n",
    "    )\n",
    "\n",
    "    result['refute_placebo_new_effect'] = refute_placebo.new_effect\n",
    "    result['refute_placebo_p_value'] = refute_placebo.refutation_result['p_value']\n",
    "    result['refute_subset_new_effect'] = refute_subset.new_effect\n",
    "    result['refute_subset_p_value'] = refute_subset.refutation_result['p_value']\n",
    "    result['refute_random_new_effect'] = refute_random.new_effect\n",
    "    result['refute_random_p_value'] = refute_random.refutation_result['p_value']\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the causal estimates result\n",
    "import joblib\n",
    "# joblib.dump(estimates, 'estimates.joblib')\n",
    "estimates = joblib.load('estimates.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the estimates and refutations\n",
    "report = []\n",
    "for feat, causal_estimate, model, identified_estimand in estimates:\n",
    "    if causal_estimate is not None:\n",
    "        res = process_causal_estimate(feat, causal_estimate, model, identified_estimand)\n",
    "        report.append(res)\n",
    "    else:\n",
    "        print(f\"No valid estimate for {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame(report)\n",
    "final_result = final_result[(final_result.refute_subset_p_value > 0.05) & (final_result.refute_random_p_value > 0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = final_result.sort_values('causal_estimate', key=abs, ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>causal_estimate</th>\n",
       "      <th>refute_placebo_new_effect</th>\n",
       "      <th>refute_placebo_p_value</th>\n",
       "      <th>refute_subset_new_effect</th>\n",
       "      <th>refute_subset_p_value</th>\n",
       "      <th>refute_random_new_effect</th>\n",
       "      <th>refute_random_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>consolidatedIncome</td>\n",
       "      <td>0.069470</td>\n",
       "      <td>2.137179e-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074794</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.069406</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>operating_return_on_assets</td>\n",
       "      <td>0.034343</td>\n",
       "      <td>-4.507505e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033614</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.034470</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppeq</td>\n",
       "      <td>0.201731</td>\n",
       "      <td>-2.223569e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216249</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.201470</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>epsDil</td>\n",
       "      <td>-0.000555</td>\n",
       "      <td>6.938894e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>issrepayEquity</td>\n",
       "      <td>0.022182</td>\n",
       "      <td>1.579639e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023679</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.022248</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   metric_name  causal_estimate  refute_placebo_new_effect  \\\n",
       "15          consolidatedIncome         0.069470               2.137179e-15   \n",
       "28  operating_return_on_assets         0.034343              -4.507505e-14   \n",
       "3                         ppeq         0.201731              -2.223569e-14   \n",
       "48                      epsDil        -0.000555               6.938894e-17   \n",
       "34              issrepayEquity         0.022182               1.579639e-14   \n",
       "\n",
       "    refute_placebo_p_value  refute_subset_new_effect  refute_subset_p_value  \\\n",
       "15                     0.0                  0.074794                   0.90   \n",
       "28                     0.0                  0.033614                   0.94   \n",
       "3                      0.0                  0.216249                   0.88   \n",
       "48                     0.0                 -0.000310                   0.94   \n",
       "34                     0.0                  0.023679                   0.96   \n",
       "\n",
       "    refute_random_new_effect  refute_random_p_value  \n",
       "15                  0.069406                   1.00  \n",
       "28                  0.034470                   0.96  \n",
       "3                   0.201470                   0.98  \n",
       "48                 -0.000628                   0.90  \n",
       "34                  0.022248                   0.90  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The placebo tests suggest that the observed effects are likely genuine,\n",
    "# as the placebo new effects are almost zero and the p-values are statistically significant.\n",
    "# The random and subset tests indicate that the causal effects are robust to random perturbations,\n",
    "# as the new effect estimates remain close to the original, and the p-values are generally not significant.\n",
    "\n",
    "final_result.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_csv('./CausalData/study_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CryptoSA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
